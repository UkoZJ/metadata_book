{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "competitive-abortion",
   "metadata": {},
   "source": [
    "# Dataset: _reports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, zipfile, io, json, re\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "\n",
    "import src.utils as ut\n",
    "\n",
    "# Setup the root path of the application\n",
    "project_path = ut.project_path()\n",
    "\n",
    "# Get contentUrl from metadata file\n",
    "meta_filename = f\"{project_path}/meta/mosquito_alert/reports.json\"\n",
    "ut.info_meta(meta_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-cambridge",
   "metadata": {},
   "source": [
    "## 1. Distribution from Zenodo cloud\n",
    "\n",
    "This dataset is updated nightly and the most recent version can be downloaded\n",
    "from Zenodo at https://doi.org/10.5281/zenodo.597466. This URL will always\n",
    "resolve to the most recent version of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata\n",
    "contentUrl, dataset_name, distr_name = ut.get_meta(\n",
    "    meta_filename, idx_distribution=0, idx_hasPart=None\n",
    ")\n",
    "\n",
    "# Make folders for data download\n",
    "path = f\"{project_path}/data/{dataset_name}/{distr_name}\"\n",
    "ut.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and open the zip container\n",
    "\n",
    "# Get the latest zenodo file version of the dataset\n",
    "r = requests.get(contentUrl)\n",
    "file_url = BeautifulSoup(r.content).find(\"a\", {\"class\": \"filename\"})[\"href\"]\n",
    "file_contentUrl = urllib.parse.urljoin(r.url, file_url)\n",
    "\n",
    "# Download the dataset\n",
    "r_file = requests.get(file_contentUrl)\n",
    "z = zipfile.ZipFile(io.BytesIO(r_file.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-stand",
   "metadata": {},
   "source": [
    "We have the option to extract all the file reports into a distribution folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-bermuda",
   "metadata": {},
   "source": [
    "Or we could concatenate all reports into a single dataframe before and save\n",
    "it as a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all reports into a dataframe\n",
    "df_reports = []\n",
    "reports = [s for s in z.namelist() if (s.find(\"all_reports\") != -1)]\n",
    "for name in reports:\n",
    "    f = z.open(name)\n",
    "    d = json.loads(f.read())\n",
    "    df_reports.append(pd.DataFrame.from_records(d, coerce_float=True))\n",
    "\n",
    "df = pd.concat(df_reports)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-whale",
   "metadata": {},
   "source": [
    "Some attributes of reports are key-value json-like data, that need additional\n",
    "tables to be fully comprehensive (for example, tiger_responses). Since\n",
    "multilanguage translations are available, we make language as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_translation = [s for s in z.namelist() if (s.find(\"translation_dict\") != -1)]\n",
    "\n",
    "f = z.open(reports_translation[0])\n",
    "r = f.read()\n",
    "\n",
    "try:\n",
    "    d = json.loads(r)\n",
    "except ValueError:\n",
    "    print(\"Warning: not a valid Json format. Try to get rid of trailing comma.\")\n",
    "try:\n",
    "    r = re.sub(r\"\\\"\\s*,\\s*\\}\", '\" }', r.decode(\"utf-8\"))\n",
    "    d = json.loads(r)\n",
    "except ValueError:\n",
    "    print(\"Json format is still not valid.\")\n",
    "\n",
    "df_reports_translation = pd.DataFrame.from_dict(d, orient=\"index\")\n",
    "df_reports_translation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reports on CSV or parquet\n",
    "filename = f\"{path}/all_reports\"\n",
    "df.to_parquet(f\"{filename}.parquet\")  # very low file-size (need to install pyArrow)\n",
    "df.to_csv(f\"{filename}.csv\")  # x10 size if compared with the dataframe\n",
    "\n",
    "# Save seports translation on CSV\n",
    "df_reports_translation.to_csv(f\"{filename}_translation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-innocent",
   "metadata": {},
   "source": [
    "## 2. Distribution from MosquitoAlert Github repository\n",
    "\n",
    "This dataset is also updated daily on GitHub and can be accessed from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata\n",
    "contentUrl, dataset_name, distr_name = ut.get_meta(\n",
    "    meta_filename, idx_distribution=1, idx_hasPart=None\n",
    ")\n",
    "\n",
    "# Make folders for data download\n",
    "path = f\"{project_path}/data/{dataset_name}/{distr_name}\"\n",
    "ut.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request reports in json format and concatenate all of them into a dataframe\n",
    "df_reports = []\n",
    "for url in contentUrl[:-1]:\n",
    "    r = requests.get(url)\n",
    "    d = r.json()\n",
    "    df_reports.append(pd.DataFrame.from_records(d, coerce_float=True))\n",
    "\n",
    "df = pd.concat(df_reports)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request other support material of the reports and put them into dataframes\n",
    "# Since multilanguage translations are available, we make language as index\n",
    "\n",
    "url = contentUrl[-1]\n",
    "r = requests.get(url)\n",
    "try:\n",
    "    d = r.json()\n",
    "except ValueError:\n",
    "    print(\"Warning: not a valid Json format. Try to get rid of trailing comma.\")\n",
    "try:\n",
    "    r = re.sub(r\"\\\"\\s*,\\s*\\}\", '\" }', r.text)\n",
    "    d = json.loads(r)\n",
    "except ValueError:\n",
    "    print(\"Json format is still not valid.\")\n",
    "\n",
    "df_reports_translation = pd.DataFrame.from_dict(d, orient=\"index\")\n",
    "df_reports_translation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reports on CSV or parquet\n",
    "filename = f\"{path}/all_reports\"\n",
    "df.to_parquet(f\"{filename}.parquet\")  # very low file-size (need to install pyArrow)\n",
    "df.to_csv(f\"{filename}.csv\")  # x10 size if compared with the dataframe\n",
    "\n",
    "# Save seports translation on CSV\n",
    "df_reports_translation.to_csv(f\"{filename}_translation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-print",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
