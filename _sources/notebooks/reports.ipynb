{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "competitive-abortion",
   "metadata": {},
   "source": [
    "# Dataset: _reports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests, zipfile, io, json, re\n",
    "\n",
    "import src.utils as ut\n",
    "\n",
    "# Setup the root path of the application\n",
    "project_path = ut.project_path()\n",
    "\n",
    "# Get contentUrl from metadata file\n",
    "meta_filename = f'{project_path}/meta/mosquito_alert/reports.json'\n",
    "ut.info_meta(meta_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-cambridge",
   "metadata": {},
   "source": [
    "## 1. Distribution from Zenodo cloud\n",
    "\n",
    "Pay attention to get the url of the most recent version of the dataset. Below\n",
    "we give an url just as an example, but probably it is not pointing to the\n",
    "most recent dataset version. However, if the dataset link is not pointing to \n",
    "the last dataset version, Zenodo issues a waring and a link to the most recent\n",
    "version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata\n",
    "contentUrl, dataset_name, distr_name = ut.get_meta(\n",
    "    meta_filename, idx_distribution=0, idx_hasPart=None)\n",
    "\n",
    "# Make folders for data download\n",
    "path = f'{project_path}/data/{dataset_name}/{distr_name}'\n",
    "ut.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and open the zip container\n",
    "r = requests.get(contentUrl)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-stand",
   "metadata": {},
   "source": [
    "We have the option to extract all the file reports into a distribution folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-bermuda",
   "metadata": {},
   "source": [
    "Or we could just concatenate all reports into a single dataframe and save\n",
    "it on a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all reports into a dataframe\n",
    "df_reports = []\n",
    "reports = [s for s in z.namelist() if (s.find('all_reports') != -1)]\n",
    "for name in reports:\n",
    "    f = z.open(name)\n",
    "    d = json.loads(f.read())\n",
    "    df_reports.append(pd.DataFrame.from_records(d, coerce_float=True))\n",
    "\n",
    "df = pd.concat(df_reports)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-whale",
   "metadata": {},
   "source": [
    "Some report attributes are key-value json-like data, that need additional\n",
    "tables to be fully comprehensive. For example, for “tiger_respones”,\n",
    "since multi language translations are available, we make language as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_translation = [s for s in z.namelist() if (s.find('translation_dict') != -1)]\n",
    "\n",
    "f = z.open(reports_translation[0])\n",
    "r = f.read()\n",
    "\n",
    "try:\n",
    "    d = json.loads(r)\n",
    "except ValueError:\n",
    "    print(\"Warning: not a valid Json format. Try to get rid of trailing comma.\")\n",
    "try:\n",
    "    r = re.sub(r\"\\\"\\s*,\\s*\\}\", \"\\\" }\", r.decode('utf-8'))\n",
    "    d = json.loads(r)\n",
    "except ValueError:\n",
    "    print(\"Json format is still not valid.\")\n",
    "\n",
    "df_reports_translation = pd.DataFrame.from_dict(d, orient='index')\n",
    "df_reports_translation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reports on CSV or parquet\n",
    "filename = f'{path}/all_reports'\n",
    "df.to_parquet(f'{filename}.parquet') # very low file-size (need to install pyArrow)\n",
    "df.to_csv(f'{filename}.csv') # x10 size if compared with the dataframe\n",
    "\n",
    "# Save seports translation on CSV\n",
    "df_reports_translation.to_csv(f'{filename}_translation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-innocent",
   "metadata": {},
   "source": [
    "## 2. Distribution from MosquitoAlert Github repository\n",
    "\n",
    "In contrast with the Zenodo distribution, the dataset stored on GitHub server is\n",
    "always the latest available version since it is daily loaded into Zenodo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata\n",
    "contentUrl, dataset_name, distr_name = ut.get_meta(\n",
    "    meta_filename, idx_distribution=1, idx_hasPart=None)\n",
    "\n",
    "# Make folders for data download\n",
    "path = f'{project_path}/data/{dataset_name}/{distr_name}'\n",
    "ut.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request reports in json format and concatenate all of them into a dataframe\n",
    "df_reports = []\n",
    "for url in contentUrl[:-1]:\n",
    "    r = requests.get(url)\n",
    "    d = r.json()\n",
    "    df_reports.append(pd.DataFrame.from_records(d, coerce_float=True))\n",
    "\n",
    "df = pd.concat(df_reports)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request other support material of the reports and put them into dataframes\n",
    "# Since multilanguage translations are available, we make language as index\n",
    "\n",
    "url = contentUrl[-1]\n",
    "r = requests.get(url)\n",
    "try:\n",
    "    d = r.json()\n",
    "except ValueError:\n",
    "    print(\"Warning: not a valid Json format. Try to get rid of trailing comma.\")\n",
    "try:\n",
    "    r = re.sub(r\"\\\"\\s*,\\s*\\}\", \"\\\" }\", r.text)\n",
    "    d = json.loads(r)\n",
    "except ValueError:\n",
    "    print(\"Json format is still not valid.\")\n",
    "\n",
    "df_reports_translation = pd.DataFrame.from_dict(d, orient='index')\n",
    "df_reports_translation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reports on CSV or parquet\n",
    "filename = f'{path}/all_reports'\n",
    "df.to_parquet(f'{filename}.parquet') # very low file-size (need to install pyArrow)\n",
    "df.to_csv(f'{filename}.csv') # x10 size if compared with the dataframe\n",
    "\n",
    "# Save seports translation on CSV\n",
    "df_reports_translation.to_csv(f'{filename}_translation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-print",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
